FEW_SHOT_RESPONSE_EXMAPLE = '0'

# GLM onehot prompts
GLM_ONEHOT_SYSTEM_INSTRUCTION = '''
You are a knowledge tracking model that predicts whether a student will be able to get a new question right when he encounters it based on his history of doing the question, and the knowledge concepts in the question.
Give the format of the history of exercising as follows, with each line representing an exercise:
\"exercise_id: exercise_id, knowledge concepts: [knowledge concepts in the exercise], is_correct: 0 or 1\".
Then, a question and corresponding knowledge points will be given, and you need to predict whether the student will be able to answer these questions correctly or not.
The output should only be 0 or 1, 1 for correct and 0 for incorrect. no other explanation is needed.
'''
GLM_ONEHOT_FEWSHOT_USER_EXAMPLE = ''''''# only used when not generated by llms
GLM_ONEHOT_PREDICT_INSTRUCTION = '''
Base on the system instructions, fewshots and information above. Only respond with only one 0 or 1 to predict the student can answer <Exercise to Predict> correctly or not.
'''
GLM_ONEHOT_ANALYSIS_INSTRUCTION = '''Analyze the student knowledge state by the exercise logs and information above.'''
GLM_ONEHOT_EXPLAINATION_INSTRUCTION = '''
Now, you are a teacher analysing the student's performance in the previous question.
The student's ability to get this question right depends on many factors, so please analyse why the student performed as shown above in the previous question in the following ways, taking into account the given record of doing the question as well as the historical analysis.
1. Find out the knowledge points involved in the new question, it will follow the format of \"knowledge concepts: ['kc1', 'kc2'...]\"

The new exercise contains <knowledge points 1>, <knowledge points 2, ...>

2. analyse the link between the question and the topic in the student's record of work: is the question new, and does the knowledge point in this question exist in previous questions? with the following format:
Similar to question <q1,q2... > or It's a new question, there is <some kind of> connection between the previous knowledge points and questions.

3. For Student's mastery of knowledge, update the knowledge state based on the current question and the previous exercises with the following format:

Student's Knowledge state:
<previous knowledge points 1, good/fair/bad>, <previous knowledge points 2, good/fair/bad>, <previous knowledge points 3, good/fair/bad> ...
<knowledge points 1 in this exercise, good/fair/bad>, <knowledge points 2 in this exercise, good/fair/bad> ...

4. whether the student mastered the knowledge points involved in the question, whether there is carelessness and other reasons to get the question wrong? with the following format:
The student gets it <right, wrong>, <almost impossible, possible, likely> because of <guessing, mastery> / <carelessness, incorrect mastery>.

Explain the result, no additional warnings or PREDICTION needed.
'''


GLM_ONEHOT_SELF_REFLECTION_INSTRUCTION = '''
'''

# GLM sparse prompts
GLM_SPARSE_SYSTEM_INSTRUCTION = '''
You are a knowledge tracking model that predicts whether a student will be able to get a new question right when he encounters it based on his history of doing the question, and the knowledge concepts in the question.
Give the format of the history of exercising as follows: each exercise information begins with <Exercise exercise_id> and ends with <END Exercise exercise_id>:

<Exercise exercise_id>
knowledge concepts: [knowledge concepts descriptions in the exercise],
is_correct: 0 or 1
<END Exercise exercise_id>

Then, a question and corresponding knowledge points will be given, and you need to predict whether the student will be able to answer these questions correctly or not.
The output should only be 0 or 1, 1 for correct and 0 for incorrect. no other explanation is needed.
'''
GLM_SPARSE_FEWSHOT_USER_EXAMPLE = ''''''# only used when not generated by llms
GLM_SPARSE_PREDICT_INSTRUCTION = '''
Base on the system instructions, fewshots and information above. Only respond with only one 0 or 1 to predict the student can answer <Exercise to Predict> correctly or not.
'''
GLM_SPARSE_ANALYSIS_INSTRUCTION = '''
Analyze the student knowledge state by the exercise logs and information above.
'''
GLM_SPARSE_EXPLAINATION_INSTRUCTION = '''
Now, you are a teacher analysing the student's performance in the previous question.
The student's ability to get this question right depends on many factors, so please analyse why the student performed as shown above in the previous question in the following ways, taking into account the given record of doing the question as well as the historical analysis.
1. Find out the knowledge points involved in the new question, it will follow the format of \"knowledge concepts: ['kc1', 'kc2'...]\"

The new exercise contains <knowledge points 1>, <knowledge points 2, ...>

2. analyse the link between the question and the topic in the student's record of work: is the question new, and does the knowledge point in this question exist in previous questions? with the following format:
Similar to question <q1,q2... > or It's a new question, there is <some kind of> connection between the previous knowledge points and questions.

3. For Student's mastery of knowledge, update the knowledge state based on the current question and the previous exercises with the following format:

Student's Knowledge state:
<previous knowledge points 1, good/fair/bad>, <previous knowledge points 2, good/fair/bad>, <previous knowledge points 3, good/fair/bad> ...
<knowledge points 1 in this exercise, good/fair/bad>, <knowledge points 2 in this exercise, good/fair/bad> ...

4. whether the student mastered the knowledge points involved in the question, whether there is carelessness and other reasons to get the question wrong? with the following format:
The student gets it <right, wrong>, <almost impossible, possible, likely> because of <guessing, mastery> / <carelessness, incorrect mastery>.

Explain the result, no additional warnings or PREDICTION needed.
'''
GLM_SPARSE_SELF_REFLECTION_INSTRUCTION = ''''''

# GLM moderate prompts
GLM_MODERATE_SYSTEM_INSTRUCTION = '''
You are a knowledge tracking model that predicts whether a student will be able to get a new question right when he encounters it based on his history of doing the question, and the knowledge concepts in the question.
Give the format of the history of exercising as follows, with each line representing an exercise:
\"exercise_id: exercise_id, 
exercise_content: exercise content, 
knowledge concepts: [knowledge concepts in the exercise], is_correct: 0 or 1\".
Then, a question and corresponding knowledge points will be given, and you need to predict whether the student will be able to answer these questions correctly or not.
The output should only be 0 or 1, 1 for correct and 0 for incorrect. no other explanation is needed.
'''
GLM_MODERATE_FEWSHOT_USER_EXAMPLE = '''''' # only used when not generated by llms
GLM_MODERATE_PREDICT_INSTRUCTION = '''
Base on the system instructions, fewshots and information above. Only respond with only one 0 or 1 to predict the student can answer <Exercise to Predict> correctly or not.
'''
GLM_MODERATE_ANALYSIS_INSTRUCTION = f'{GLM_SPARSE_ANALYSIS_INSTRUCTION}'
GLM_MODERATE_EXPLAINATION_INSTRUCTION = f'{GLM_SPARSE_EXPLAINATION_INSTRUCTION}'
GLM_MODERATE_SELF_REFLECTION_INSTRUCTION = ''''''


# GPT onehot prompts
GPT_ONEHOT_SYSTEM_INSTRUCTION = f'{GLM_ONEHOT_SYSTEM_INSTRUCTION}'
GPT_ONEHOT_FEWSHOT_USER_EXAMPLE = f'{GLM_ONEHOT_FEWSHOT_USER_EXAMPLE}'
GPT_ONEHOT_PREDICT_INSTRUCTION = '''
Base on the system instructions, fewshots and information above, predict the student can answer the last <Exercise to Predict> correctly or not. Only respond with one 0 or 1.
'''
GPT_ONEHOT_ANALYSIS_INSTRUCTION = f'{GLM_ONEHOT_ANALYSIS_INSTRUCTION}'
GPT_ONEHOT_EXPLAINATION_INSTRUCTION = f'{GLM_ONEHOT_EXPLAINATION_INSTRUCTION}'
GPT_ONEHOT_SELF_REFLECTION_INSTRUCTION = f'{GLM_ONEHOT_SELF_REFLECTION_INSTRUCTION}'

# GPT sparse prompts
GPT_SPARSE_SYSTEM_INSTRUCTION = f'{GLM_SPARSE_SYSTEM_INSTRUCTION}'
GPT_SPARSE_FEWSHOT_USER_EXAMPLE = f'{GLM_SPARSE_FEWSHOT_USER_EXAMPLE}'
GPT_SPARSE_PREDICT_INSTRUCTION = '''
Base on the system instructions, fewshots and information above, predict the student can answer the last <Exercise to Predict> correctly or not. Only respond with one 0 or 1.
'''
GPT_SPARSE_ANALYSIS_INSTRUCTION = f'{GLM_SPARSE_ANALYSIS_INSTRUCTION}'
GPT_SPARSE_EXPLAINATION_INSTRUCTION = f'{GLM_SPARSE_EXPLAINATION_INSTRUCTION}'
GPT_SPARSE_SELF_REFLECTION_INSTRUCTION = f'{GLM_SPARSE_SELF_REFLECTION_INSTRUCTION}'

# GPT moderate prompts
GPT_MODERATE_SYSTEM_INSTRUCTION = '''
You are a teacher that predicts and analyze whether a student will be able to get a new question right when he encounters it based on his history of doing the question, and the knowledge concepts in the question.
Give the format of the history of exercising as follows, with each line representing an exercise:
\"exercise_id: exercise_id, 
exercise_content: exercise content, 
knowledge concepts: [knowledge concepts in the exercise], is_correct: 0 or 1\".
Then, a question and corresponding knowledge points will be given, and you need to predict whether the student will be able to answer these questions correctly or not.
The output should only be 0 or 1, 1 for correct and 0 for incorrect. no other explanation is needed.
'''
GPT_MODERATE_FEWSHOT_USER_EXAMPLE = ''''''
GPT_MODERATE_PREDICT_INSTRUCTION = '''
Base on the system instructions, fewshots and information above. Only respond with only one 0 or 1 to predict the student can answer the last <Exercise to Predict> correctly or not.
'''
GPT_MODERATE_ANALYSIS_INSTRUCTION = f'{GLM_MODERATE_ANALYSIS_INSTRUCTION}'
GPT_MODERATE_EXPLAINATION_INSTRUCTION = f'{GLM_MODERATE_EXPLAINATION_INSTRUCTION}'
GPT_MODERATE_SELF_REFLECTION_INSTRUCTION = f'{GLM_MODERATE_SELF_REFLECTION_INSTRUCTION}'


model_oh_sys_instr = {
    'glm': GLM_ONEHOT_SYSTEM_INSTRUCTION,
    'gpt': GPT_ONEHOT_SYSTEM_INSTRUCTION
}
model_oh_fewshot_u_ex = {
    'glm': GLM_ONEHOT_FEWSHOT_USER_EXAMPLE,
    'gpt': GPT_ONEHOT_FEWSHOT_USER_EXAMPLE
}
model_oh_fewshot_s_ex = {
    'glm': FEW_SHOT_RESPONSE_EXMAPLE,
    'gpt': FEW_SHOT_RESPONSE_EXMAPLE
}
model_oh_predict_instr = {
    'glm': GLM_ONEHOT_PREDICT_INSTRUCTION,
    'gpt': GPT_ONEHOT_PREDICT_INSTRUCTION
}
model_oh_analysis_instr = {
    'glm': GLM_ONEHOT_ANALYSIS_INSTRUCTION,
    'gpt': GPT_ONEHOT_ANALYSIS_INSTRUCTION
}
model_oh_explain_instr = {
    'glm': GLM_ONEHOT_EXPLAINATION_INSTRUCTION,
    'gpt': GPT_ONEHOT_EXPLAINATION_INSTRUCTION
}
model_oh_self_refl_instr = {
    'glm': GLM_ONEHOT_SELF_REFLECTION_INSTRUCTION,
    'gpt': GPT_ONEHOT_SELF_REFLECTION_INSTRUCTION
}
model_sp_sys_instr = {
    'glm': GLM_SPARSE_SYSTEM_INSTRUCTION,
    'gpt': GPT_SPARSE_SYSTEM_INSTRUCTION
}
model_sp_fewshot_u_ex = {
    'glm': GLM_SPARSE_FEWSHOT_USER_EXAMPLE,
    'gpt': GPT_SPARSE_FEWSHOT_USER_EXAMPLE
}
model_sp_fewshot_s_ex = {
    'glm': FEW_SHOT_RESPONSE_EXMAPLE,
    'gpt': FEW_SHOT_RESPONSE_EXMAPLE
}
model_sp_predict_instr = {
    'glm': GLM_SPARSE_PREDICT_INSTRUCTION,
    'gpt': GPT_SPARSE_PREDICT_INSTRUCTION
}
model_sp_analysis_instr = {
    'glm': GLM_SPARSE_ANALYSIS_INSTRUCTION,
    'gpt': GPT_SPARSE_ANALYSIS_INSTRUCTION
}
model_sp_explain_instr = {
    'glm': GLM_SPARSE_EXPLAINATION_INSTRUCTION,
    'gpt': GPT_SPARSE_EXPLAINATION_INSTRUCTION
}
model_sp_self_refl_instr = {
    'glm': GLM_SPARSE_SELF_REFLECTION_INSTRUCTION,
    'gpt': GPT_SPARSE_SELF_REFLECTION_INSTRUCTION
}

model_mo_sys_instr = {
    'glm': GLM_MODERATE_SYSTEM_INSTRUCTION,
    'gpt': GPT_MODERATE_SYSTEM_INSTRUCTION
}
model_mo_fewshot_u_ex = {
    'glm': GLM_MODERATE_FEWSHOT_USER_EXAMPLE,
    'gpt': GPT_MODERATE_FEWSHOT_USER_EXAMPLE
}
model_mo_fewshot_s_ex = {
    'glm': FEW_SHOT_RESPONSE_EXMAPLE,
    'gpt': FEW_SHOT_RESPONSE_EXMAPLE
}
model_mo_predict_instr = {
    'glm': GLM_MODERATE_PREDICT_INSTRUCTION,
    'gpt': GPT_MODERATE_PREDICT_INSTRUCTION
}
model_mo_analysis_instr = {
    'glm': GLM_MODERATE_ANALYSIS_INSTRUCTION,
    'gpt': GPT_MODERATE_ANALYSIS_INSTRUCTION
}
model_mo_explain_instr = {
    'glm': GLM_MODERATE_EXPLAINATION_INSTRUCTION,
    'gpt': GPT_MODERATE_EXPLAINATION_INSTRUCTION
}
model_mo_self_refl_instr = {
    'glm': GLM_MODERATE_SELF_REFLECTION_INSTRUCTION,
    'gpt': GPT_MODERATE_SELF_REFLECTION_INSTRUCTION
}


def generic_get_prompts(model_name:str, data_mode:str):
    # TODO: add more prompts for different data modes!!!
    # TODO: support different LLMs!!!
    # data_mode: onehot, sparse, moderate, rich
    # return a dictionary of prompts
    # keys: sys_instr, fewshot_u_ex, fewshot_s_ex, predict_instr, analysis_instr, explain_instr, self_refl_instr

    if data_mode == 'onehot':
        return {
            'sys_instr': model_oh_sys_instr[model_name],
            'fewshot_u_ex': model_oh_fewshot_u_ex[model_name],
            'fewshot_s_ex': model_sp_fewshot_s_ex[model_name],
            'predict_instr': model_oh_predict_instr[model_name],
            'analysis_instr': model_oh_analysis_instr[model_name],
            'explain_instr': model_oh_explain_instr[model_name],
            'self_refl_instr': model_oh_self_refl_instr[model_name]
        }
    elif data_mode =='sparse':
        return {
            'sys_instr': model_sp_sys_instr[model_name],
            'fewshot_u_ex': model_sp_fewshot_u_ex[model_name],
            'fewshot_s_ex': model_sp_fewshot_s_ex[model_name],
            'predict_instr': model_sp_predict_instr[model_name],
            'analysis_instr': model_sp_analysis_instr[model_name],
            'explain_instr': model_sp_explain_instr[model_name],
            'self_refl_instr': model_sp_self_refl_instr[model_name]
        }
    elif data_mode =='moderate':
        return {
            'sys_instr': model_mo_sys_instr[model_name],
            'fewshot_u_ex': model_mo_fewshot_u_ex[model_name],
            'fewshot_s_ex': model_mo_fewshot_s_ex[model_name],
            'predict_instr': model_mo_predict_instr[model_name],
            'analysis_instr': model_mo_analysis_instr[model_name],
            'explain_instr': model_mo_explain_instr[model_name],
            'self_refl_instr': model_mo_self_refl_instr[model_name]
        }
    elif data_mode == 'rich':
        raise NotImplementedError
    else:
        raise ValueError(f'Invalid data_mode {data_mode}, when getting prompts.')